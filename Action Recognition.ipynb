{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcamCuuyjYb2"
   },
   "source": [
    "# Action Recognition @ UCF101  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random \n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import random\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# torch.cuda.is_available()\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UdCRwkL7jxtc"
   },
   "source": [
    "---\n",
    "---\n",
    "## **Problem 1.** Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vignesh Ram Nithin\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "actions = pd.read_csv('annos/actions.txt',sep='  ',header = None)\n",
    "actions.columns = ['category_num','category_name']\n",
    "labels_subsets = pd.read_csv('annos/videos_labels_subsets.txt',sep='\\t',header=None)\n",
    "labels_subsets.columns = ['video_name','category_num','train/test']\n",
    "# labels_subsets.merge(labels_subsets,actions, on='category_num')\n",
    "labels_subsets_sample = labels_subsets[labels_subsets['category_num']<26]\n",
    "train_df = labels_subsets_sample[labels_subsets_sample['train/test']==1].reset_index(drop=True)\n",
    "test_df = labels_subsets_sample[labels_subsets_sample['train/test']==2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urKQi8oAjYb-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "features = list(vgg16.classifier.children())[:-6] # Remove last layer\n",
    "vgg16.classifier = nn.Sequential(*features)\n",
    "vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, isTrain,images_path,transform=None):\n",
    "        self.data = data\n",
    "        self.images_path = images_path\n",
    "        self.labels = self.data['category_num']\n",
    "#         self.height = 48\n",
    "#         self.width = 48\n",
    "        self.transform = transform\n",
    "        self.transform_label = transforms.Compose([transforms.ToTensor()])\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(index)\n",
    "        # This method should return only 1 sample and label \n",
    "        # (according to \"index\"), not the whole dataset\n",
    "        # So probably something like this for you:\n",
    "        \n",
    "        video_name = self.data['video_name'][index]\n",
    "        video_label = self.data['category_num'][index]\n",
    "        images_name = []\n",
    "        \n",
    "        for i in os.listdir(os.path.join(self.images_path,video_name)):\n",
    "            images_name.append(os.path.join(self.images_path,video_name,i))\n",
    "\n",
    "        imgs = [Image.open(i) for i in images_name]\n",
    "\n",
    "        images=[]\n",
    "\n",
    "        transformed_imgs = []\n",
    "        if self.transform is not None:\n",
    "            for k in range(25):\n",
    "#                 print(imgs[k].size)\n",
    "                transformed_imgs.append(self.transform(imgs[k]))\n",
    "        \n",
    "        label = [torch.Tensor(video_label) for i in range(125)]\n",
    "        \n",
    "        return transformed_imgs, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "images_path = 'images'\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "\n",
    "    transforms.FiveCrop((224,224)),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) (crop) for crop in crops])),\n",
    "\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_df,1,images_path,train_transform)\n",
    "test_dataset = CustomDataset(test_df,0,images_path,train_transform)\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for i,(data,label) in enumerate(train_loader):\n",
    "    if i<1800:\n",
    "        continue\n",
    "#     elif i>=1800:\n",
    "#         break\n",
    "\n",
    "    data = torch.stack(data).squeeze(1).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(25):\n",
    "            features.append(vgg16.eval()(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file1 = open('train_features_1800-2408.pkl', 'wb')\n",
    "# # file3 = open('train_features_1800-2408.pkl','wb')\n",
    "# # file2 = open('train_features_900-1799.pkl','wb')\n",
    "pickle.dump( features, file1)                      \n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file1 = open('train_features_0-899.pkl', 'rb')\n",
    "train1 = pickle.load(file1)\n",
    "file1.close()\n",
    "file2 = open('train_features_900-1799.pkl','rb')\n",
    "train2 = pickle.load(file2)\n",
    "file2.close()\n",
    "file = open('train_features_1800-.pkl','rb')\n",
    "train = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('test_features.pkl','rb')\n",
    "test = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train1+train2+train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.stack(train)\n",
    "test = torch.stack(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare inputs for the LSTM network\n",
    "#taking average of the five crops and obtaining a one single feature vector for each of the image\n",
    "train = torch.mean(train,1)\n",
    "test = torch.mean(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the features vectors for grouping the 25 images with time stamps for an action\n",
    "\n",
    "train = train.view(int(train.shape[0]/25),25,train.shape[1])\n",
    "test = test.view(int(test.shape[0]/25),25,test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file1 = open('train_features_final.pkl','wb')\n",
    "pickle.dump( train, file1)\n",
    "file1.close()\n",
    "file2 = open('test_features_final.pkl','wb')\n",
    "pickle.dump(test,file2)\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UN74WLWpl7zQ"
   },
   "source": [
    "***\n",
    "***\n",
    "## **Problem 2.** Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('train_features_final.pkl','rb')\n",
    "train = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('test_features_final.pkl','rb')\n",
    "test = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0EGU31IJn5_h",
    "outputId": "b3541df6-f994-4f0f-ffde-d63430381e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data is : torch.Size([2409, 25, 4096])\n",
      "Shape of test/validation data is : torch.Size([951, 25, 4096])\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training data is :', train.shape)\n",
    "print('Shape of test/validation data is :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "class CustomLSTMdata(Dataset):\n",
    "    def __init__(self, data,labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        input_data = self.data[index]\n",
    "        label =self.labels[index]\n",
    "        \n",
    "        return input_data,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomLSTMdata(train,train_df['category_num'])\n",
    "test_dataset = CustomLSTMdata(test,test_df['category_num'])\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(4096,256,batch_first=True)\n",
    "        self.fc1 = nn.Linear(256,25)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x,states = self.lstm(x)\n",
    "        x = (x[:,-1,:])\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(4096, 256, batch_first=True)\n",
      "  (fc1): Linear(in_features=256, out_features=25, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTM()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 104.86027604341507\n",
      "1 43.782252103090286\n",
      "2 28.192734837532043\n",
      "3 18.437121704220772\n",
      "4 12.184323690831661\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def trainLSTM(model,train,labels,num_epochs=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "#     optimizer_ft = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
    "    optimizer_ft = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs.to(device,dtype=torch.float)), Variable(labels.to(device,dtype=torch.long))\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer_ft.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            labels = labels-1\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "#             print(loss)\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        print(epoch,running_loss)\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model\n",
    "\n",
    "model_trained = trainLSTM(model,train_loader,train_df['category_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2409, 102400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.008, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
       "          multi_class='ovr', penalty='l2', random_state=5, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "train_svm = train.view(train.shape[0],train.shape[1]*train.shape[2])\n",
    "test_svm = test.view(test.shape[0],test.shape[1]*test.shape[2])\n",
    "print(train_svm.shape)\n",
    "clf = LinearSVC(random_state=5,penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=0.08, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, max_iter=10000)\n",
    "clf.fit(train_svm.cpu(),train_df['category_num'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0znm2TMmsDZ"
   },
   "source": [
    "---\n",
    "---\n",
    "## **Problem 3.** Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARtMhcbXmsXk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate(model,test):\n",
    "    actual_label = []\n",
    "    pred_label = []\n",
    "\n",
    "    for i in test:\n",
    "        img,label = i\n",
    "        with torch.no_grad():\n",
    "            images,labels = Variable(img.to(device,dtype=torch.float)), Variable(label.to(device,dtype=torch.long))\n",
    "            model = model.float()\n",
    "            pred = model(images)\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            pred = [predicted[j].item()+1 for j in range(len(labels))]\n",
    "            actual_label.extend(label)\n",
    "            pred_label.extend(pred)\n",
    "    return (accuracy_score(actual_label,pred_label))\n",
    "\n",
    "test_accuracy_LSTM = evaluate(model_trained,test_loader)\n",
    "train_accuracy_LSTM = evaluate(model_trained,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = clf.predict(train_svm.cpu())\n",
    "test_pred = clf.predict(test_svm.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80ZUeqnGv48f"
   },
   "source": [
    " ### The train and test accuracy of LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 100.000: 0.9867164798671648\n",
      "Test accuracy is 100.000 : 0.8128286014721346\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy is %2.3f:' %(100.00),train_accuracy_LSTM)\n",
    "print('Test accuracy is %2.3f :' %(100.00),test_accuracy_LSTM )\n",
    "# lr = 0.001\n",
    "# batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eesNQn6FYKQz"
   },
   "source": [
    " ### The train and test accuracy of SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ip87hPqTYJtr",
    "outputId": "62743d24-ce79-4a89-e42f-f4af278235d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 100.000 : 1.0\n",
      "Test accuracy is 100.000 : 0.825446898002103\n"
     ]
    }
   ],
   "source": [
    "train_svm_accuracy = accuracy_score(train_pred,train_df['category_num'])\n",
    "test_svm_accuracy = accuracy_score(test_pred,test_df['category_num'])\n",
    "\n",
    "\n",
    "print('Training accuracy is %2.3f :' %(100.00), train_svm_accuracy )\n",
    "print('Test accuracy is %2.3f :' %(100.00), test_svm_accuracy )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "CSE527_HW5_fall18_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
